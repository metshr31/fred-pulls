name: Scheduled Daily Scrape

on:
  # Run at 2:00 AM Eastern Time daily
  schedule:
    - cron: '0 7 * * *' 
  # Allows manual run from the Actions tab
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: â¬‡ï¸ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: ğŸ“¦ Install dependencies
        run: |
          # Use Playwright's native installation method
          pip install playwright beautifulsoup4 python-dateutil
          # Install the necessary browsers for Playwright
          playwright install chromium --with-deps

      - name: âš™ï¸ Run the scraper script
        run: |
          # Use the Playwright script and pass today's date automatically
          # GitHub runner uses UTC, so running at 7:00 UTC gets yesterday's US-published data.
          TARGET_DATE=$(date -u --date 'yesterday' +%Y-%m-%d)
          python scrape_investing_transcripts_playwright.py --date $TARGET_DATE --out transcripts.txt

      - name: ğŸ“¤ Commit and push results
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "ğŸ¤– Daily scrape update for ${{ steps.run-script.outputs.date }}"
          # Only commit the output file
          file_pattern: transcripts.txt
          # Use a GitHub Token that has write access
          token: ${{ secrets.GITHUB_TOKEN }}
